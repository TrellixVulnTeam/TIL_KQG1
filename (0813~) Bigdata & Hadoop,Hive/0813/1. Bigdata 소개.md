# 빅데이터 저장 기술

-  신뢰성 있고, 확장성 있는 분산 컴퓨팅을 위한 오픈소스 프레임워크
-  간단한 프로그래밍 모델을 사용하여 대용량 데이터의 분산 처리를 할 수 있는 프레임워크
-  GFS, MapReduce 소프트웨어구현체
  - ​    \- 아파치Top-Level 프로젝트
  - ​    \- 코어는 Java, C/C++, Python 등 지원
-  대용량 데이터 처리를 위한 플랫폼
  - ​    \- 분산파일시스템(HDFS)
  - ​    \- 분산병렬처리시스템(MapReduce)
  - ​    \- 기반소프트웨어프레임워크(Core)

### GFS 개발 배경

- 저가형 서버로 구성된 환경  -> 서버의 고장이 빈번히 발생 가능 (장애 허용 이유)
- 파일은 대용량 파일을 가정  -> 대용량 파일을 효과적으로 관리할 수 있는 방법이 요구
- 작업 부하는 주로 연속적으로 많은 데이터를 읽는 연산이거나 임의의 영역에서 적은 데이터를 읽는 연산으로 구성
- 파일에 대한 쓰기 연산은 주로 순차적으로 데이터를 추가하는 연산이며 파일에 대한 수정은 드물게 이루어짐
- 동시에 동일한 파일에 데이터를 추가하는 환경에서 동기화 오버헤드를 최소화할 수 있는 방법이 요구.
- 낮은 응답 지연 시간보다 높은 처리율이 좀 더 중요.

###  GFS 특징

- 파일은 Chunk 단위(64MB)로 저장
- 기본 3군데(3개의 node) 이상 저장을 통한 신뢰성 확보
  - 마스터 노드 - slave 노드로 구성
- 단일 마스터를 통한 접근 제어 및 메타 데이터의 중앙 관리
- 대용량 데이터 집합과 스트리밍 읽기에 따른 가시 기능 삭제
- 단순하고 친숙한 인터페이스와 API 커스터마이징 제공

## Hadoop 모듈

###  Hadoop 파일 시스템의 장/단점

-  특징 및 장점
  - 선형적인 확장성 제공

  - 글로벌 네임스페이스 제공

  - 비용절감
  - 데이터분석 처리에 활용

- 일반적인 파일 시스템과 다른 특징과 제약사항
  - 응용프로그램 기반의 파일 시스템

  - 불변 파일만 저장 (Once write many read)
  - NameSpace 관리를 NameNode 메모리에 저장
  - 전체 처리 용량증가
  - NameNode 이중화 문제
  - Namenode(master)가 죽으면?

###  Hadoop 설계 목표

- 장애복구
  - 복제 데이터 저장
  - 주기적인 상태 체크

- 스트리밍 방식의 데이터 접근
  - 높은 데이터 처리량에 중점을 두고 있음

- 대용량 데이터 저장
  - 하나의 파일이 테라바이트 이상 저장 가능
  - 하나의 인스턴스에서 수백만 개 이상의 파일 지원

-  데이터 무결성
  - 읽기 전용

  - 파일 이동, 삭제, 복사 인터페이스 제공

![hadooarch](https://user-images.githubusercontent.com/50945713/62922995-b992a000-bde7-11e9-8c20-32e3fd106f06.png)



 ### HDFS(Hadoop Distributed File System)

- 파일의 분산 저장이 목적

- Namenodes와 Datanodes로 구성

  - Master Namenode
  - Secondary Namenode

  - Datanode

- 저렴한 컴퓨터로 대 용량 데이터를 저장할 수 있는 시스템
  - 네트워크 Raid와 같이 연결된 것 처럼 사용하는 하드디스크
  - Scale Out

-  Block(Chunk) 단위로 파일관리 (저장/복제/삭제)
  - Default Size는 64M

-  복제기능을 통해 안전성/신뢰성을 보장

-  1대의 Master서버에 4000+이상의 Datanodes를 운영할 수 있음.

- API지원
  - 하둡 코어는 Python, Java, C/C++