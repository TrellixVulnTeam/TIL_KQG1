- vorg.apache.hadoop.util.GenericOptionsParser

     하둡 콘솔 명령에서 입력한 옵션을 분석합니다.

     네임노드, 잡트래커, 추가 구성 자원 등을 설정할 수 있는 옵션 제공

     getRemainingArgs() : String[]

     GenericOptionsParser에서 제공하는 파라미터를 제외한 나머지 파라미터를 반환  

- vorg.apache.hadoop.util.Tool

  ​    GenericOptionsParser의 콘솔 설정 옵션을 지원하기 위한 인터페이스

  ​     interface Tool extends Configurable

  ​    드라이버 클래스 정의 시 Configured를 상속받고, Tool 인터페이스를 구현

  ​    public class DelayCount extends Configured implements Tool

  ​     Configured 클래스는 환경설정 정보를 제어할 수 있게 합니다.

  ​    Tool 인터페이스는 사용자의 옵션을 조회할 수 있게 합니다.  

- vorg.apache.hadoop.util.ToolRunner

  ​	출발 지연을 할거냐 도착 지연을 할거냐를 정하는 클래스를 만들수 있다. (옵션 설정으로)

  ​    Tool 인터페이스의 실행을 도와주는 헬퍼 클래스

  ​     GenericOptionsParser를 사용해 사용자가 콘솔 명령어에서 설정한 옵션을 분석하고, Configuration 객체에 설정합니다.

  ​    Configuration 객체를 Tool 인터페이스에 전달한 후, Tool 인터페이스의 run() 메서드를 실행합니다.

  ​    ToolRunner.run(Cunfiguration conf, Tool tool, String[] args) 메서드를 이용해 Tool의 run() 메서드를 실행합니다.



### 정렬(Sorting)

- 맵리듀스의 핵심 기능
  - 하나의 리듀스 태스크만 실행되게 하면 정렬을 쉽게 해결할 수 있지만, 여러 데이터 노드가 구성된 상황에서 하나의 리듀스 태스크만 실행하는 것은 분산 환경의 장점을 살리지 않는 것입니다.
  - 대량의 데이터를 정렬하게 될 경우 네트워크 부하도 상당함
  - 하둡이 제공하는 정렬 방식
     <u>보조 정렬(Secondary Sort)</u>
     부분 정렬(Partial Sort)
     전체 정렬(Total Sort)

- 보조 정렬(Secondary Sort)
  - 키의 값들을 그룹핑하고, 그룹핑된 레코드에 순서를 부여하는 방식
  - 구현 순서
     기존 키의 값들을 조합한 복합키(Composite Key) 정의
     키의 값 중에서 그룹핑 키로 사용할 키 결정
     복합키의 레코드를 정렬하기 위한 비교기(Comparator) 정의
     그룹핑 키를 파티셔닝할 파티셔너(Partitioner) 정의
     그룹핑 키를 정렬하기 위한 비교기(Pomparator) 정의



---



DelayCountReducer.java

```java
package lab.hadoop.delaycount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

public class DelayCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
	 private IntWritable result = new IntWritable();
	 
	 public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException{
		 int sum = 0;
		 for( IntWritable value:values)
			 sum += value.get();
		 result.set(sum);
		 context.write(key, result);
	 }

}

```



DelayCountMapper.java

```java
package lab.hadoop.delaycount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class DelayCountMapper extends Mapper<LongWritable,Text, Text,IntWritable> {
	
	private String workType;
	
	private final static IntWritable outputValue = new IntWritable(1);
	private Text outputKey = new Text();
	@Override
	public void setup (Context context) 
			throws IOException, InterruptedException {
		
		
	}
	public void map (LongWritable key, Text value, Context context) {
		if (key.get()>0) {
			String [] colums = value.toString().split(",");
			if(colums !=null && colums.length>0) {
				try {
					if (workType.equals("departure")) {
						if(!colums[15].equals("NA")) {
							int depDelayTime= Integer.parseInt(colums[15]);
							if(depDelayTime>0) {
								outputKey.set(colums[0] + ","+colums[1]);
								context.write(outputKey, outputValue);
							}
						}
					}else if (workType.equals("arrival")) {
						if(!colums[14].equals("NA")) {
							int arrDelayTime=Integer.parseInt(colums[14]);
							if(arrDelayTime>0) {
								
							}
						}
					}
				}catch (Exception e) {
					e.printStackTrace();
				}
			}
		}		
	}
}
```

DelayCount.java

```java
package lab.hadoop.delaycount;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.Writable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

public class DelayCount extends Configured implements Tool {
	@Override
	public int run(String[] args) throws Exception {
		String [] otherArgs= new GenericOptionsParser(getConf(), args).getRemainingArgs();
		
		
		if (otherArgs.length!=2) {
			System.err.println("Usage : DelayCount <in> <out>");
			System.exit(2);
		}
		Job job = new Job(getConf(),"DelayCount");
		
		FileSystem hdfs = FileSystem.get(getConf());
		
		Path path = new Path(args[1]);
		if (hdfs.exists(path)) {
		hdfs.delete(path, true);	
		}
		
		FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
		FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
		
		job.setJarByClass(DelayCount.class);
		
		job.setMapperClass(DelayCountMapper.class);
		
		job.setReducerClass(DelayCountReducer.class);
		
		job.setInputFormatClass(TextInputFormat.class);
		job.setOutputFormatClass(TextOutputFormat.class);
		
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(Writable.class);
		
		job.waitForCompletion(true);
		
		return 0;
	
	}
	public static void main (String[] args) throws Exception {
		int res = ToolRunner.run(new Configuration(), new DelayCount(), args);
		System.out.println("## RESULT :"+res);	
	}
}
```

