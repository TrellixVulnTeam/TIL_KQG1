## Hadoop 동작 모드

### 유사분산모드

- 한 대의 서버 상에 HDFS를 사용한 MapReduce 동작 환경을 구축한다.
- NameNode 프로세스, DataNode 프로세스 모두 한 대의 서버 상에서 동작
- JobTracker 프로세스, Task Tracker 프로세스 모두 한 대의 서버상에서 동작
- HDFS/MapReduce 동작 검증, Hadoop 애플리케이션 기능 검증



### 완전 분산 모드

- 여러 대의 서버 상에 HDFS를 사용한 MapReduce 동작환경을 구축한다.
- 상용 환경 구축, 노드 간 통신을 포함한 HDFS/MapReduce 동작 검증, 성능 등의 비기능 요건을 포함한 애플리케이션 검즘

## NameNode

- 입력되는 파일에 대한 저장소 선택, 복제 개수 지정 등 데이터 노드를 관리한다
- MasterNode로 파일에 대한 메타 데이터를 저장하는 노드로, 
  디렉터리 구조, 파일에 대한 각종 메타 데이터, 그리고 물리적 파일이 저장되어 있는 위치 등을 저장.
- CheckPoint 관리를 수행 ( 주기적으로 상태 체크로 빠르게 장애 인지 및 대처)
- fsimage :: 파일 위치에 대한 매칭과 속성 등 namespace를 저장
- editlog : 파일 입출력에 대한 트랜잭션 로그를 저장

## Secondary Namenode(보조 네임노드)

- 네임노드의 fsimage, editlog 스냅샷 저장
- 보조네임노드는 Master서버 (네임노드) 장애시 복구하기 위한 기능 X
- Hadoop 재가동시 editlog의 트랜잭션로그를 다시 작성해주는 역할

## DataNode

- 실제 파일을 저장/읽기 수행. 
  하나의 파일을 블록이라는 단위로 나눠서 저장하는 역할
- Block단위는 임의 설정이 가능. Default는 64MB
- 네임노드와 주기적으로 통신해 저장하고 있는 블록에 대한 정보를 네임노드에 저장하도록 합니다.
- 데이터 노드에 저장된 파일들은 정책에 의해 자동 분산 저장되고 1대node에 장애가 나도 서비스에 영향은 없다.

### 파일 시스템(fsimage)

- 파일 시스템에 존재하는 모든 디렉토리와 파일 아이노드 정보를 바이트로 직렬화한 파일
  각 아이노드는 파일이나 디렉터리의 내부적인 표현이며 파일의 복제 단위. 변경 및 접근시간, 접근권한, 블록크기와 파일을 구성하는 블록 조합들 같은 정보를 가진다.
  디렉터리는 변경시간, 권한, 할당크기 같은 메타데이터가 저장됨

### HDFS 동작 방식

![hdfs동작 방식](https://user-images.githubusercontent.com/50945713/63640178-2e16ea00-c6d8-11e9-9d7d-7c40849bae3c.png)

1. (클라이언트) 네임 노드로 파일 패스에 대한 생성을 요청합니다.
2. (네임 노드) 메모리상에 해당 파일의 패스 정보를 생성하고 락(Lock)을 겁니다.
3. (네임 노드) 파일 데이터를 저장할 데이터 노드를 선택해 데이터 노드 목록을 클라이언트로 반환합니다.
4. (클라이언트) 첫 번째 데이터 노드로 전송하는 데이터의 첫 부분에 데이터 노드의 목록을 같이 포함하여 데이터를 전송합니다.
5. (데이터 노드) 데이터를 받은 첫 번째 데이터 노드는 데이터를 로컬 디스크에 저장하고 다음데이터 노드로 데이터를 전송합니다. 이런 방식으로 두 번째 데이터 노드는 세 번째 데이터 노드로 복제본을 생성합니다.
6. (클라이언트) 정해진 블록 크기를 넘어서면 클라이언트는 네임 노드로 새로운 데이터 노드를 요청합니다.
7. (네임 노드) 메모리에 임시로 저장돼 있던 파일의 패스 정보를 메모리상에 있는 영구 파일 패스 정보로 이동시킵니다. 그리고 네임 노드 재시작 시에도 패스에 대한 정보가 존재하도록 네임 노드의 로컬 디스크에 파일 생성 관련 로그(edits)를 저장합니다.
8. (네임 노드) 클라이언트의 새로운 블록 생성 요청에 대해 블록을 저장할 데이터 노드 목록을 전달합니다.
9. (클라이언트) 4번~6번 과정을 반복합니다.
10. (클라이언트) 파일 전송이 완료되면 close () 명령을 네임 노드로 전달합니다.
11. (세컨드리 네임 노드) 주기적으로 7번에서 저장하고 있는 edits 파일을 네임 노드로 부터 다운로드 해서 네임스페이스 정보를 저장하고 있는 fsimage 파일 과 병합해 새로운fsimage 파일을 생성해 네임 노드로 전송합니다. 
12. (네임 노드) 기존의 fsimage 파일을 새로운 파일로 대체하고 edits 파일을 새로운 파일로 만듭니다.
13. (네임 노드) 시작 시에는 fsimage 파일을 읽어 메모리를 구성한 후 edits 파 일의 변경 대역을 하나씩 수행하는 방식으로 메모리를 재구성합니다.

### Secondary Node동작 방식

![secondary node](https://user-images.githubusercontent.com/50945713/63640475-bb0f7280-c6db-11e9-98e6-2e40cc914ff0.png)

1. (네임노드) 세컨드리 네임노드는 네임 노드에 edits 로그 파일을 순환 사용하도록 요청합니다. 그 때문에 새로운 edits 로그는 새로운 edits 로그 파일에 저장됩니다.
2. (세컨드리 네임노드) HTTP GET을 이용해서 네임노드의 fsimage와 edits 로그를 가져옵니다.
3. (세컨드리 네임노드) fsimage를 메모리에 올리고 edits 로그의 각 동작을 반영합니다. 그리고 나서 새롭게 통합된 fsimage 파일을 생성합니다.
4. (세컨드리 네임노드) HTTP GET을 이용해서 새로운 fsimage 파일을 네임노드에 전송합니다.
5. (네임노드) 이전 fsimage 파일을 세컨드리 네임노드로부터 받은 새로운 이미지로 교체하며, 이전 edits 로그 파일을 1단계에서 시작한 새로운 edits 로그 파일로 교체합니다. fsimage 파일도 체크 포인트가 발생한 시간을 기록하기 위해 변경됩니다.

- 보조 네임노드는 네임노드의 인-메모리 메타데이터에 체크포인트를 생성합니다.

### Zookeeper

![zookeeper](https://user-images.githubusercontent.com/50945713/63640529-691b1c80-c6dc-11e9-9ece-a3d19b895807.png)

1. 클러스터 시작 시에 ,한대의 노드를 리더로 선출
2. 클라이언트가 zookeeper에 데이터 갱신 요청 전송
3. 요청을 leader에 전송
4. leader는 갱신 처리에 트랜잭션 ID부여, 모든 노드에 요청 전송
5. 각 노드는 갱신 데이터를 저널 로그에 기록, 리더에게 응답을 반환
6. 리더는 과반수의 노드로부터 응답이 돌아온 시점에 기록 처리 성공으로 간주해 클라이언트에게 commit 명령 반환

---

## Hadoop 클러스터 구성 환경

### 하둡 환경 설정 파일

- hadoop-env.sh
  : 하둡을 실행하는 쉘 스크립트 파일에서 필요한 환경변수 설정
  홈 디렉토리의 아래에 bin 아래에 쉘 스크립트 파일이 사용
  JDK경로, 클래스 패스, 데몬 실행 옵션 등 다양한 환경 변수 설정 가능
- slaves
  : 데이터 노드를 실행할 서버 설정. 데이터 노드가 여려개라면 라인단위로 서버이름을 설정
- core-site.xml
  : HDFS와 맵리듀스에서 공통적으로 사용할 환경정보 설정
- hdfs-site.xml
  : HDFS에서 사용할 환경 정보 설정
- mapred-site.xml
  : 맵리듀스에서 사용할 환경정보 설정
- yarn-site.xml
  : 맵리듀스 프레임워크에서 사용하는 셔플 서비스지정

---

## HDFS 관리

### hdfs fs - 옵션

```
파일 목록 보기 : ls, lsr
파일 용량 확인 : du, dus
파일 내용 보기 : cat, text
디렉토리 생성 : mkdir
파일 복사 : put, get, getmerge,  cp, copyFromLocal,  copyToLocal
파일 이동 : mv, moveFromLocal
카운트 값 조회 : count
파일삭제, 디렉토리 삭제 : rm,  rmr
파일의 마지막 내용 확인 : tail
권한 변경 : chmod, chown,  chgrp
0바이트파일 생성 : touchz
통계 정보 조회 : stat
복제 데이터 개수 변경 : setrep
휴지통 비우기 : expunge
파일 형식 확인 : test
```

- 지정한 디렉토리의 목록 보기
  $ hadoop fs -ls /

- 지정한 디렉토리와 그 하위 디렉토리의 목록보기
  $ hadoop fs -lsr /

- 디렉토리 생성(하둡 내부 파일시스템(hdfs)에 사용자 디렉토리 생성
  $ hadoop fs -mkdir /usr/data

- 디렉토리와 파일별로 용량을 출력
  $ hadoop fs -du /usr

- 전체 합계 용량 출력
  $ hadoop fs -dus /usr

- 파일 복사
  $ hadoop fs -put ./lab/airports.csv /usr/data
  $ hadoop fs -put ./lab /usr

- 디렉토리 삭제
  $ hadoop fs -rmr /usr/lab

- 지정한 디렉토리와 그 하위 디렉토리 삭제
  $ hadoop fs -lsr /usr

### 파일 병합

```
$ pwd
$ hadoop fs -get -ignoreCrc /usr/lab/sample.txt
$ ls
$ hadoop fs -cat /usr/lab/sample.txt
$ hadoop fs -cat /usr/lab/sample2.txt
$ hadoop fs -mkdir /usr/merge
$ hadoop fs -mv /usr/lab/sample* /usr/merge
$ hadoop fs -ls /usr/lab
$ hadoop fs -ls /usr/merge
$ hadoop fs -getmerge /usr/merge ./sample3
$ ls
$ cat sample3
```



### 안전모드

- 하둡 실행 후 ^z 또는 ^s와 같이 비정상 종료 시 hadoop은 default로 safe모드로 진입함.
  이때 hdfs를 조작하면 다음 에러 메세지 출력함.Ø org.apache.hadoop.hdfs.server.namenode.SafeModeException:
  Cannot delete /output. Name node is in safemode.

- 안전모드에서 파일시스템 메타데이터로의 접근은 정상 동작.
  파일 변경 (쓰기, 삭제 , 이름변경)은 항상 실패

- 안전모드 진입과 해제

  ```
  hadoop dfsadmin -safemode get
  hadoop dfsadmin -safemode wait
  hadoop dfsadmin -safemode enter
  hadoop dfsadmin -safemode leave
  ```

### 도구

- dfsadmin
  : hdfs상태 정보 조회 및 hdfs상에서 다양한 관리 동작 수행하는 다목적 도구

- dfsadmin -help

  fsck : 파일 시스템 상태 체크
  balancer : HDFS 재균형
  daemonlog : 로그 레벨 동적 변경
  dfsadmin : HDFS상태 확인, HDFS 퇴거, DataNode참가 등

- fsck :파일시스템 점검

  - 모든 데이터 노드를 점검하여 사라지거나, 적게 또는 많이 복제된 블록을 찾아줌

  - HDFS 상의 다양한 불일치(블록 누락, 복제 되지 않은 블록)를 확인

  - 오류를 발견하고 수정하지는 않음(NameNode가 복구가능한 오류는 자동으로 수정)

  - 열린 파일은 무시함 

### 로깅

- log4j는 자바기반 로깅 유틸리티.
  디버그용 도구로 주로 사용됨

- 설정 파일에 대상별 레벨 지정이 가능하고 그 등급 이상의 로그만 저장하는 방식

- 하둡은 log4j로그 설정파일로 로그 수준 지정 가능

- 로그레벨

  - FATAL, ERROR, WARN, INFO, DEBUG, TRACE

  - ```
    [hadoop@master hadoop]$ vi log4j.properties
    # Custom Logging levels
    #log4j.logger.org.apache.hadoop.mapred.JobTracker=DEBUG
    #log4j.logger.org.apache.hadoop.mapred.TaskTracker=DEBUG
    #log4j.logger.org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit=DEBUG
    ```

### 클러스터에서 노드 추가

1. include 파일에 새 노드의 네트워크 주소 추가
   dfs.hosts와 mapreduce.jobtracker.hosts.filename속성을 통해 하나의 공유 파일을 참조
2. 네임노드에 허가된 데이터 노드 집합 반영
   $ hadoop dfsadmin-refreshNodes
3. 새로 허가된 태스크트래커 집합을 잡트래커에 반영한다
   $ hadoop mradmin -refreshNodes
4. 새 노드가 하둡제어 스크립트에 의해 장치 클러스터에서 사용될 수 있게 slaves파일 갱신
5. 새로운 데이터 노드와 테스크 트래커를 시작
6. 새로운 데이터 노드와 테스크 트래커가 웹UI에 나타나는지 확인

### 클러스터에 노드 삭제

1. 해제할 노드의 네트워크 주소를 exclude 파일에 추가한다. 이때 include 파일은 수정하지 않는다.

   hosts.include파일
   hosts.exclude 파일
   hdfs-site.xml 에 hosts와  hosts.exclude  property 설정 

2. 허가된 새로운 데이터 노드 집합을 가지고 네임노드를 갱신한다.
   $ hadoop dfsadmin -refreshNodes

3. 허가된 새로운 태스크 트래커 집합을 가지고 잡 트래커를 갱신한다.
   $ hadoop mradmin -refreshNodes

4. 웹 UI에 접속해서 해제할 데이터 노드의 관리 상태가"Decommissinoning in Progress"로 변했는지 확인한다.

5. 모든 데이터 노드가 블록 복사를 완료하면 관리 상태가"Decommissioned"로 변한다.

6. include 파일에서 해당 노드를 삭제하고 나서 실행한다.
   $ hadoop dfsadmin -refreshNodes
   $ hadoop mradmin -refreshNodes
7. salves 파일에서 해당 노드를 지운다..