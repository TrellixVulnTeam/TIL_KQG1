## MapReduce Programming

![mapreduce](https://user-images.githubusercontent.com/50945713/63650353-cec2e380-c784-11e9-8ab3-c3d423ed2727.png)

- 병렬처리를 지원하기 위해 개발
- 함수형 프로그래밍 map(), Reduce() 함수 기반으로 주로 구성
  - map() 
    : (key, value) 상을 처리해 또 다른 (key,value) 쌍을 생성하는 함수
  - Reduce()
    : 맵으로부터 생성된 (key,list(value))들을 병합(merge)하여 최종적으로 list(value)들을 생성하는 함수
- 데이터 처리를 위한 프로그래밍 모델
- 분산컴퓨팅에 적합한 함수형 프로그래밍
- 배치형 데이터 처리 시스템
- 자동화된 병렬처리 및 분산처리
- Fault- tolerance (내고장성, 결함허용)
- 프로그래머를 위한 추상클래스

### Job

- 데이터 집합을 이용해 Mapper와 Reducer를 실행하는 "전체 프로그램"
  20개 파일로부터 "Word Count"실행은 1개의 Job(작업)

### Task

- 1개의 데이터 조각을 처리하는 1개의Mapper 또는Reducer의 실행
  20개의 파일은 20개의 Map 태스크에 의해 처리됨

### Task Attempt

- 머신 위에서 1개의 태스크를 실행하는 특정 시도
  최소 20개의 맵테스크 시도들이 수행됨. 서버 장애시 더 많음

### Map

- 어떤 데이터의 집합을 받아들여 데이터를 생성하는 프로세스
  주로 입력 파일을 한 줄씩 읽어서 filtering등의 처리 수행

### Reduce

- Map에 의해 만들어진 데이터를 모아서 최종적으로 원하는 결과로 만들어내는 프로세스
- 데이터 집약 처리
- 어떤 처리든 데이터는 키 & 밸류의 쌍으로 이루어지고 해당 쌍의 집합을 처리함
- 입력 데이터 & 출력 데이터는 키-밸류 집합으로 구성됨
- Shuffle
  - Map처리 후 데이터를 정렬해 같은 키를 가진 데이터를 같은 장소에 모은다.
    슬레이브 서버 간에 네트워크를 통한 전송이 발생

![tasktracker](https://user-images.githubusercontent.com/50945713/63650286-f82f3f80-c783-11e9-9055-2f52198fff7f.png)

### Job Tracker

- 클라이언트로부터 작업 요청 받으면 실행
- Task Tracker의 작업 할당 및 결과 통합
- 상태 및 전체 작업 진행 상황 등을 지속적으로 감시
- 마스터노드에서 시작

### Task Tracker

- 슬레이브노드에서 실행
- 태스크를 실행할 자바 프로세스 발생
- 최대 몇 개의 태스크를 동시 수용할지는 사용자가 Hadoop 설정을 통해 지정 가능
- 최대 태스크 개수는 Map Task와 Reduce Task별로 지정 가능

## Data Flow : 

#### 1단계 Input & Map

- MapReduce를 이용해 할 수 있는 작업
  - 카운터
    : 입력파일 중 조건에 맞는 데이터 수를 count
  - 분산 grep
    : 파일에서 특정 문자열을 포함하는 행을 찾는 프로그램
  - 분산 sort
    : 입력데이터를 임의의 순서로 정렬

#### 2단계 : 파티셔닝 & 셔플

#### 3단계 : Reduce & Output

![process](https://user-images.githubusercontent.com/50945713/63650416-a2f42d80-c785-11e9-9b13-4b34eb6bb4f6.png)

### Hadoop MapReduce 프로그래밍 요소

- 데이터타입

  맵 리듀스 프로그램에서 키와 값으로 사용되는 데이터 타입
  반드시 **WritableComparable** 인터페이스를 구현해야함

- InputFormat

  입력 스플릿을 맵 메서드의 입력 파라미터로 사용할 수 있도록 함

- Partitioner

  맵 태스크의 출력 데이터가 어떤 리듀스 태스크로 전달될지 결정

- OutputFormat

  setOutputFormatClass 메서드로 설정하는 맵 리듀스 잡의 출력 데이터 포맷

### HDFS 접근 - FileSystem

- org.apache.hadoop.fs.FileSystem

- 하둡에서 제공하는 파일 시스템을 추상화 한 클래스입니다.

- 로컬 파일 시스템이나 HDFS나 어떤 파일 시스템을 사용하든 반드시 FileSystem 클래스로 파일에 접근해야 합니다

- 객체 생성

  - Configuration conf = new Configuration();
    FileSystem hdfs = FileSystem.get(conf);
    Path path = new Path("파일시스템 경로");

  또는

  - Path path = new Path("파일시스템 경로");
    FileSystem fs = path.getFileSystem(getConf());

- 파일 시스템 경로
  상대경로는 /user/hadoop 디렉토리 기준

### **org.apache.hadoop.mapreduce.Mapper**

- public void setup(Mapper.Context context)
  map 메소드가 호출되기 전에 먼저 딱 한번 호출되는 메소드
  map 메소드에서 필요한 리소스를 할당
  map에서 필요한 선행 작업을 수행
  분산 캐시(Distributed Cache)파일 오픈
- public void cleanup(Mapper.Context context)
  map 호출이 완료되면 (모든 입력 레코드가 처리되면) 마지막으로 한번 호출
  setup메서드에서 할당한 리소스 해제
  분산 캐시(Distributed Cache)파일 close
- public void run(Mapper.Context context)
  Mapper 클래스의 전체 구동 함수

### **TextInputFormat**

- FileInputFormat에서 상속받음
- 텍스트 파일 대상이며 .gz로 압축된 것도 처리합니다.
- 텍스트 라인 하나가 하나의 레코드에 해당합니다.
- 해당 라인의 파일오프셋이 Key가 됩니다.
- Key의 타입은 <u>LongWritable</u>입니다.
- 해당 라인 전체가 Value가 됩니다.
- Value의 타입은 <u>Text</u>입니다.
- Job 클래스의 setInputFormatClass 메서드로 다른 입력 포맷(KeyValueTextInputFormat, SequenceFileInputFormat)으로 변경할 수 있습니다.
- 입력 파일들의 위치는 FileInptFormat 클래스의 addInputPath 메소드로 지정 호출합니다.
- 하둡 프로그램의 입력과 출력은  HDFS 상의 파일(디렉토리)이 됩니다.
- 맵의 출력 레코드들의 Key와 Value 타입은 Job 클래스의 setMapOutputKeyClass 메서드와 setMapOutputValueClass 메서드로 프레임워크에 알려주어야 합니다.
- Identity Mapper와 Identity Reducer 
  - 맵이나 리듀스가 필요없는 경우에 사용
  - 주어진 입력 레코드(Key, Value)를 <u>그대로 출력 레코드로 내보내</u>는 단순한 맵 클래스와 리듀스 클래스
- 어떤 타입이 맵이나 리듀스에서 Key로 사용되기 위해서는 WritableComparable인터페이스를 지원해야 하고, Value로 사용되기 위해서는 Writable 인터페이스를 구현해야 합니다.
- Writable 인터페이스는 <u>직렬화/역직렬화(serializable/deserializable)</u>를 구현하는데 사용되는 메소드를 갖고 있습니다
  - 하둡의 Key/Value 레코드는 디스크에 저장되거나 네트워크를 타고 전달되어야 하므로 직렬화/역직렬화가 필요합니다.
  - 하둡은 RPC(Remote Procedure Call)를 이용해서 클러스터 내의 노드들 간에 통신을 수행하므로 직렬화/역직렬화가 필요합니다.
  - write 메서드 -  객체  직렬화(serializable)
  - readFileds 메서드 – 객체 역직렬화( deserializable)
- WritableComparable인터페이스는 <u>객체들간의 비교</u>를 가능하게 해주기 위한 자바의 Comparable 인터페이스가 추가된 인터페이스
  - 하둡에서 맵과 리듀스에서 사용되는 키들은 소팅이 가능해야 합니다.
  - Comparable 인터페이스의 compareTo 메서드는 객체를 비교하여  순서를 정해주는 역할을 합니다.

![basetype](https://user-images.githubusercontent.com/50945713/63650636-a4bef080-c787-11e9-8e24-582d4c18eacf.png)

### KeyValueTextInputFormat

- 하나의 레코드를 해석할 때 Key와 Value 사이에 <u>TAB</u>  문자와 같은 분리자가 있다고 가정합니다
- Tab이 아닌 다른 분리자를 사용해야 한다면 하둡 Job의 환경설정(Configuration) 인스턴스의 set 메서드를 호출하여 'key.value.separator.in.input.line' 프로퍼티의 값을 다른 분리자로 설정해야 합니다.
- Key와 Value의 타입은 모두 <u>Text</u>가 됩니다.

### SequenceInputFormat

- <u>하둡의 고유 파일 포맷</u>은 시퀀스 파일입니다.
- 어떤 타입이든 Key와 Value로 사용 가능합니다.
- <u>MapFile</u>을 읽는데도 사용할 수 있습니다.
- MapFile은 <u>디렉토리</u>이고 그 안에 인덱스 파일과 데이터 파일이 각각 시퀀스 파일의 형태로 존재합니다.

### MultipleInputs

- 서로 다른 포맷의 입력 파일들간에 <u>공통의 키</u>가 존재하고 같은 키를 갖는 레코드들끼리 <u>묶어서 조인</u>을 수행하고 싶은 경우 사용
- 입력 파일의 경로에 따라 다른 입력 포맷과 맵 클래스를 지정할 수 있습니다.

### Map Task **수의 결정 방식**

- 주어진 입력 파일을 처리하기 위해 필요한 맵 태스크의 수는 <u>프레임워크가 알아서 정한다</u>
- 입력 포맷이 주어진 입력 파일들을 처리하는데 몇 개의 맵 태스크가 필요한지 결정
- getSplits 메서드 - 주어진 모든 입력 파일들을 입력 파일 수와 입력 파일의 크기 정보를 바탕으로 InputSplit로 나눠서 그 조각들의 리스트를 리턴
- InputSplit 마다 맵 태스크가 하나씩 할당 (하나의 데이터 블록마다 할당)
- 어떤 포맷들은 파일이 여러 블록으로 구성이 되어 있어도 블록별로 맵 태스크를 할당하는 것을 불허합니다.  (TextInputFormat의 경우 텍스트 파일이 <u>gzip 등으로 압축이 되어 있으면</u> 전체 파일을 블록의 수와 관계 없이 <u>하나의 맵 태스크에 지정</u>해 버립니다.)
- isSplitable 메서드는 블록 단위로 나눌 수 있는지 여부를 반환합니다.

### Combiner

- Mini Reducer, Local Reducer

- 맵 태스크의 출력에 리듀스 코드를 먼저 적용해서 리듀스로 넘어가야 하는 데이터의 크기를 줄이는 역할을 담당합니다.

- 맵 태스크와 리듀스 태스크 간의 네트워크 통신량을 최소화

- 작업의 순서를 달리해도 최종 결과물이 같은 잡이면 combiner를 적용할 수 있습니다. (교환의 법칙과 결합의 법칙이 만족되는 잡이라면 combiner를 적용할 수 있습니다.)

- Combiner를 적용할 수 있는 경우라면 리듀스 클래스를 그대로 컴바이너 클래스로 사용하는 형태를 가져가기를 권장합니다.

- Combiner의 설정은 Job 클래스의 setCombinerClass 메서드로 가능합니다.

  

​	



