#### 분산 컴퓨팅 필요 조건

1. 장애 허용 -  분산 클러스터 노드 중 하나가 문제가 생겨도 메인 컴퓨팅 프로세스에  부정적인 영향 주지 않아야 한다. (프로세스 실패가 발생하지 않아야 한다)
2. 복구능력 - 분산 클러스터 노드에서 수행중인 작업이 실패하더라도 작업으로부터 어떤 데이터도 손실 되어서는 안된다.
3. 선형적 확장성 - 컴퓨팅 능력, 스토리지 공간 확장등, 성능도 선형적으로 증가해야 합니다.

#### 하둡 아키텍처 

​	: HDFS, Yarn, MapReduce, API

#### 하둡 클러스터 

​	: 하둡분산파일시스템(HDFS)과 클러스터 리소스 매니저(Yarn)를 기반으로 하는 하둡 소프트웨어를 사용하는 컴퓨터들의 집합

Hadoop 2.0 부터 마스터노드 2개 이상 구성하여 고가용성(HA)를 지원합니다.

#### 마스터노드 (Active, Standby)

- 하둡 클러스터의 작업을 중재
- 하둡 클라이언트는 파일을 저장, 읽고, 처리하려면 master노드에 접속합니다
- namenode가 구성되고, 파일을 저장, 쓰기 요청에 대해서 파일시스템의 메타 정보 관리
- map reduce 작업의 중재하는 프로세스 JobTracker가 구성

#### 워커노드 (슬레이브 노드)

- 마스터 노드의 지시를 받아서 명령을 수행 (실제 데이터를 저장하고, 데이터 처리 프로레싱하는 노드)





#### HDFS

: HDFS의 storage를 관리

- NameNode - HDFS 파일 시스템의 디렉토리 트리와 파일의 위치 등 HDFS storage 관련 메타 정보(블럭 데이터를 데이터 노드에 매핑)를 관리 
  파일, 디렉토리, 생성, 열기, 쓰기 오퍼레이션 수행
  어떤 데이터노드에 복제되고, 복제 후에 삭제할지 결정
  데이터 노드에서 보내온 heartbeat와 block report를 처리 (블록 위치 유지, DataNode 상태 관리)
- SecondaryNameNode - HDFS 스토리지 메타 정보 업데이트, 세컨더리 네임노드는 설정값에 따라 기본 한시간에 한번씩 Edits 로그를 확인하면서 설정값이상의 파일이나, 트랜잭션 횟수를 넘어서면 Edits 파일을 정리하여 사이즈를 줄여줍니다. ( 기본 1시간 간격, fsimage파일과 editlog 파일을 merge)
- DataNode - 마스터 노드에 접속 유지, 3초 간격으로  heartbit, block report를 주기적으로 전송, 마스터 노드의 요청을 처리 (block 저장, block 삭제)
  로컬 파일 시스템에 블록을 저장
  데이터에 대한 읽기, 쓰기 수행
  데이터 블록 생성 및 삭제 수행
  클러스터에 데이터 블럭 복제
  주기적으로 heartbeat와 block report 전송



#### Yarn 서비스

- resource manager 
  : 마스터 노드에서 실행, 클러스터의 리소스를 나눠주는 역할, Task Tracker들의 Task를 스케줄링

- node manager 
  : 워커 노드에서 실행, Task 들을 실행시키고 관리, resource manager와관계 유지, 테스트 상태, 노트 상태 관리

- application manager
  : 클러스터에서의 메인이 되는 마스터 프로세스로서 어플리케이션별로 하나씩 실행됨, 클러스터에서 실행되는 어플리케이션의 실행 조율, 리소스 매니저와 통신(관계 유지)하면서 리소스 조절

  

하둡 클러스터에서 장애 허용과 복구 능력을 위해 sharding, replication을 수행합니다
배치 처리, 파일기반처리 (map의 처리 결과도 map처리된 datanode에 파일로 저장, reducer의 출력 결과도 HDFS에 저장, disk 기반, steam기반, sequencial 하게 처리)



---

참고 : https://yookeun.github.io/java/2015/05/24/hadoop-hdfs/	